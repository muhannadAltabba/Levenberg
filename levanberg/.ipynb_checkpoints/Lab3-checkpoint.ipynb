{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def sigmoid(Z):  \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)    \n",
    "    return dZ\n",
    "\n",
    "\n",
    "\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)          \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1])*0.02\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))      \n",
    "    dw = []\n",
    "    for i in range(L - 1):\n",
    "        dw.append(np.zeros(parameters['W' + str(i + 1)].shape))\n",
    "    return parameters, dw\n",
    "\n",
    "\n",
    "def linear_forward(A, W, b):  \n",
    "    Z = W.dot(A) + b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n",
    "\n",
    "def L_model_forward(X, parameters, activ):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                 \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = activ[l-1])\n",
    "        caches.append(cache)\n",
    "    \n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = activ[L-1])\n",
    "    caches.append(cache)          \n",
    "    return AL, caches\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    cost = np.squeeze(cost)         \n",
    "    return cost\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def L_model_backward(AL, Y, caches, activ):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = activ[L - 1])\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = activ[l])\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate, momentom, dw):\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)] - momentom * dw[l]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        dw[l] = learning_rate * grads[\"dW\" + str(l+1)] + momentom * dw[l]\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(X, y, parameters, activ):\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 \n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    probas, caches = L_model_forward(X, parameters, activ)\n",
    "\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "            \n",
    "    print(\"Accuracy: \"  + str((np.sum((p == y)/m )*100)) + \"%\")\n",
    "        \n",
    "    return p\n",
    "\n",
    "\n",
    "def weight_inflate(W):\n",
    "    return W[::-1]\n",
    "\n",
    "def levenperg_Marquardt_backward(AL, Y, caches, activ):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    dAL = -1\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = activ[L - 1])\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = activ[l])\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads\n",
    "\n",
    "def L_layer_model_levenperg(X_train, Y_train, activ, layers_dims, momentom, learning_rate = 0.75, epochs = 200, print_cost=False,batch_size=1):#lr was 0.009\n",
    "   \n",
    "    #np.random.seed(1)\n",
    "    parameters, dw = initialize_parameters_deep(layers_dims)\n",
    "\n",
    "    E = []\n",
    "   \n",
    "    wlen = 0\n",
    "    \n",
    "    blen = 0\n",
    "    costs=[]\n",
    "    m = X_train.shape[1]\n",
    "    k = m // batch_size\n",
    "    for i in range(epochs):\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuffled_X = X_train[:, permutation]\n",
    "        shuffled_Y = Y_train[:, permutation].reshape((Y_train.shape[0],m))\n",
    "        Ji = []\n",
    "        Bi = []\n",
    "        E = np.zeros(k)\n",
    "        cnt = 0\n",
    "        sum = 0\n",
    "        for X, Y, j in zip(batch(shuffled_X, batch_size), batch(shuffled_Y, batch_size), range(k)):\n",
    "            AL, caches = L_model_forward(X, parameters, activ)\n",
    "            L = len(caches) \n",
    "            cost = squared_error(Y,AL)\n",
    "            sum+=cost\n",
    "            e = Y - AL \n",
    "            e = 1 / k * np.sum(e)\n",
    "            E[cnt]+=e\n",
    "            cnt+=1\n",
    "            if print_cost and i % (epochs/10) == 0:\n",
    "                print (f\"Cost after epoch {i} batch {j}: {cost}\")\n",
    "            grads = levenperg_Marquardt_backward(AL, Y, caches, activ)\n",
    "\n",
    "           # parameters = update_parameters(parameters, grads, learning_rate, momentom, dw)\n",
    "\n",
    "            dw = []\n",
    "            db = []\n",
    "            \n",
    "            dW = []\n",
    "            dB = []\n",
    "            for l in range(L):\n",
    "                dw = grads[\"dW\" + str(l+1)]\n",
    "                db= grads[\"db\" + str(l+1)]\n",
    "                dw = dw.ravel()\n",
    "                db = db.ravel()\n",
    "                for w in dw:\n",
    "                    dW.append(w)\n",
    "                for b in db:\n",
    "                    dB.append(b)\n",
    "\n",
    "            wLen = len(dW)    \n",
    "            bLen = len(dB)\n",
    "\n",
    "            bArray = np.array(dB,copy=True)\n",
    "            wArray = np.array(dW,copy=True)\n",
    "\n",
    "\n",
    "            bArray = bArray.reshape(bLen,1)\n",
    "            wArray = wArray.reshape(wLen,1)\n",
    "\n",
    "            Ji.append(wArray.ravel())\n",
    "            Bi.append(bArray.ravel())\n",
    "\n",
    "\n",
    "        costs.append(sum / k)\n",
    "        J = np.array(Ji).T\n",
    "        B = np.array(Bi).T\n",
    "        E.reshape((E.shape[0] , 1))\n",
    "        \n",
    "        first = np.dot(J.T,J)\n",
    "        second = np.diag(np.array([learning_rate]*first.shape[0]))\n",
    "        third = first + second\n",
    "        third = np.linalg.inv(third)\n",
    "        fourth = third.dot(J.T)\n",
    "        fifth = fourth.T.dot(E)\n",
    "\n",
    "        first1 = np.dot(B.T,B)\n",
    "        second1 = np.diag(np.array([learning_rate]*first1.shape[0]))\n",
    "        third1 = first1 + second1\n",
    "        third1 = np.linalg.inv(third1)\n",
    "        fourth1 = third1.dot(B.T)\n",
    "        fifth1 = fourth1.T.dot(E)\n",
    "        parameters = update_parameters2(parameters, fifth , fifth1)\n",
    "        \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n",
    "def update_parameters2(parameters, W , B):\n",
    "    \n",
    "    wIndex = 0\n",
    "    bIndex = 0\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(L):\n",
    "        w = parameters[\"W\" + str(l+1)]\n",
    "        b = parameters[\"b\" + str(l+1)]\n",
    "        \n",
    "        for  i in range(w.shape[0]):\n",
    "            for j in range(w.shape[1]):\n",
    "                w[i][j] -= W[wIndex]\n",
    "                wIndex+=1\n",
    "        for  i in range(b.shape[0]):\n",
    "            b[i] -= B[bIndex]\n",
    "            bIndex+=1\n",
    "       \n",
    "        parameters[\"W\" + str(l+1)] = w\n",
    "        parameters[\"b\" + str(l+1)] = b\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "def squared_error(Y,A):\n",
    "    return 1/2* np.sum(np.power(Y-A, 2))\n",
    "\n",
    "def squared_error_tert(Y, A):\n",
    "    return -1\n",
    "\n",
    "def load_planar_dataset():\n",
    "    np.random.seed(1)\n",
    "    m = 400 # number of examples\n",
    "    N = int(m/2) # number of points per class\n",
    "    D = 2 # dimensionality\n",
    "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
    "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
    "    a = 4 # maximum ray of the flower\n",
    "\n",
    "    for j in range(2):\n",
    "        ix = range(N*j,N*(j+1))\n",
    "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
    "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        Y[ix] = j\n",
    "        \n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def load_datasets():  \n",
    "    np.random.seed(1)\n",
    "    N = 200\n",
    "    noisy_circles = sklearn.datasets.make_circles(n_samples=N, factor=.5, noise=.3)\n",
    "    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n",
    "    blobs = sklearn.datasets.make_blobs(n_samples=N, random_state=5, n_features=2, centers=6)\n",
    "    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n",
    "    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n",
    "    \n",
    "    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure\n",
    "\n",
    "\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
    "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(X[0, :], X[1, :], c=y, cmap=plt.cm.Spectral)\n",
    "\n",
    "def batch(X, batch_size):\n",
    "    n = X.shape[1] // batch_size\n",
    "    for i in range(n):\n",
    "        if batch_size != 1:\n",
    "            yield X[:, batch_size * i:batch_size * (i + 1)]\n",
    "        else:\n",
    "            yield X[:, batch_size * i:batch_size * (i + 1)].reshape(X.shape[0], 1)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_circle, noisy_moon, blobes, gaus, no_structure = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y,parameters,activ):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[0, :].min() - 2, X[0, :].max() + 2\n",
    "    y_min, y_max = X[1, :].min() - 2, X[1, :].max() + 2\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    Z = predict(X.ravel(),y.ravel(),parameters,activ)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(X[:,0], X[:,1], c=y.ravel(), cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 200)\n",
      "(1, 200)\n"
     ]
    }
   ],
   "source": [
    "train_x_orig, train_y = noisy_circle\n",
    "train_x = train_x_orig.T\n",
    "train_y = train_y.reshape(1,train_y.shape[0])\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0 batch 0: 1.2499993878112772\n",
      "Cost after epoch 0 batch 1: 1.2500004593260743\n",
      "Cost after epoch 0 batch 2: 1.250000439718573\n",
      "Cost after epoch 0 batch 3: 1.250000717188339\n",
      "Cost after epoch 0 batch 4: 1.2499995025681412\n",
      "Cost after epoch 0 batch 5: 1.2500006116914626\n",
      "Cost after epoch 0 batch 6: 1.2499997976597446\n",
      "Cost after epoch 0 batch 7: 1.2500004800577469\n",
      "Cost after epoch 0 batch 8: 1.2500010378867366\n",
      "Cost after epoch 0 batch 9: 1.250000872224617\n",
      "Cost after epoch 0 batch 10: 1.250001161821763\n",
      "Cost after epoch 0 batch 11: 1.2500002373808505\n",
      "Cost after epoch 0 batch 12: 1.2499997360582702\n",
      "Cost after epoch 0 batch 13: 1.2500007212401565\n",
      "Cost after epoch 0 batch 14: 1.2500006816925393\n",
      "Cost after epoch 0 batch 15: 1.249999760596647\n",
      "Cost after epoch 0 batch 16: 1.25000049837426\n",
      "Cost after epoch 0 batch 17: 1.2500005070086906\n",
      "Cost after epoch 0 batch 18: 1.2500008748471845\n",
      "Cost after epoch 0 batch 19: 1.2500024177324236\n",
      "Cost after epoch 700 batch 0: 0.47243898821369834\n",
      "Cost after epoch 700 batch 1: 0.5589493102294606\n",
      "Cost after epoch 700 batch 2: 0.4376349468403615\n",
      "Cost after epoch 700 batch 3: 0.6364149271879498\n",
      "Cost after epoch 700 batch 4: 0.2683712433900695\n",
      "Cost after epoch 700 batch 5: 0.3705602766471168\n",
      "Cost after epoch 700 batch 6: 0.8529462022561067\n",
      "Cost after epoch 700 batch 7: 0.08147836795856171\n",
      "Cost after epoch 700 batch 8: 0.5272855630626847\n",
      "Cost after epoch 700 batch 9: 0.4844723799498824\n",
      "Cost after epoch 700 batch 10: 1.0736884714373338\n",
      "Cost after epoch 700 batch 11: 0.6832924206200778\n",
      "Cost after epoch 700 batch 12: 1.0176944561474426\n",
      "Cost after epoch 700 batch 13: 0.39356165211511174\n",
      "Cost after epoch 700 batch 14: 0.554193540066452\n",
      "Cost after epoch 700 batch 15: 0.6125191522766633\n",
      "Cost after epoch 700 batch 16: 1.1822206918301859\n",
      "Cost after epoch 700 batch 17: 0.14274866429145477\n",
      "Cost after epoch 700 batch 18: 1.009550213678546\n",
      "Cost after epoch 700 batch 19: 1.0502311130509123\n",
      "Cost after epoch 1400 batch 0: 0.7567335927419363\n",
      "Cost after epoch 1400 batch 1: 0.5458297965365904\n",
      "Cost after epoch 1400 batch 2: 0.343274728172092\n",
      "Cost after epoch 1400 batch 3: 0.8810457261825109\n",
      "Cost after epoch 1400 batch 4: 0.6041341874007158\n",
      "Cost after epoch 1400 batch 5: 1.1246646284572173\n",
      "Cost after epoch 1400 batch 6: 0.38403641294280655\n",
      "Cost after epoch 1400 batch 7: 0.9760772280002694\n",
      "Cost after epoch 1400 batch 8: 0.3454489615700004\n",
      "Cost after epoch 1400 batch 9: 0.6818694382452495\n",
      "Cost after epoch 1400 batch 10: 0.43673992343066886\n",
      "Cost after epoch 1400 batch 11: 0.7560440100914138\n",
      "Cost after epoch 1400 batch 12: 0.23366383324804013\n",
      "Cost after epoch 1400 batch 13: 0.9442194067714867\n",
      "Cost after epoch 1400 batch 14: 0.7263852838841889\n",
      "Cost after epoch 1400 batch 15: 0.6493694758540092\n",
      "Cost after epoch 1400 batch 16: 0.3723940252248954\n",
      "Cost after epoch 1400 batch 17: 0.6188018490176759\n",
      "Cost after epoch 1400 batch 18: 0.2537783914800768\n",
      "Cost after epoch 1400 batch 19: 0.8016595770992468\n",
      "Cost after epoch 2100 batch 0: 0.8864808705471087\n",
      "Cost after epoch 2100 batch 1: 0.7141004694863728\n",
      "Cost after epoch 2100 batch 2: 0.5515308991368499\n",
      "Cost after epoch 2100 batch 3: 0.19603301847766036\n",
      "Cost after epoch 2100 batch 4: 0.6458543542871465\n",
      "Cost after epoch 2100 batch 5: 0.6323089144269533\n",
      "Cost after epoch 2100 batch 6: 0.5574603154435577\n",
      "Cost after epoch 2100 batch 7: 1.3095234759431533\n",
      "Cost after epoch 2100 batch 8: 0.5290008114718416\n",
      "Cost after epoch 2100 batch 9: 0.06179688485100171\n",
      "Cost after epoch 2100 batch 10: 1.0121399857867184\n",
      "Cost after epoch 2100 batch 11: 0.5274133470445768\n",
      "Cost after epoch 2100 batch 12: 0.6498452915132024\n",
      "Cost after epoch 2100 batch 13: 0.5706898151205787\n",
      "Cost after epoch 2100 batch 14: 0.7661028757954355\n",
      "Cost after epoch 2100 batch 15: 0.11331343552629065\n",
      "Cost after epoch 2100 batch 16: 0.7056601338992565\n",
      "Cost after epoch 2100 batch 17: 0.3880491420745435\n",
      "Cost after epoch 2100 batch 18: 0.3477349838526255\n",
      "Cost after epoch 2100 batch 19: 1.1576655091694947\n",
      "Cost after epoch 2800 batch 0: 1.4103194737055613\n",
      "Cost after epoch 2800 batch 1: 0.5832983241240604\n",
      "Cost after epoch 2800 batch 2: 0.3272634641402232\n",
      "Cost after epoch 2800 batch 3: 0.7241587868557977\n",
      "Cost after epoch 2800 batch 4: 0.8715374308680373\n",
      "Cost after epoch 2800 batch 5: 0.5777748606907241\n",
      "Cost after epoch 2800 batch 6: 0.687975760473455\n",
      "Cost after epoch 2800 batch 7: 0.21056009127294265\n",
      "Cost after epoch 2800 batch 8: 0.5834784071217811\n",
      "Cost after epoch 2800 batch 9: 0.6165364670869345\n",
      "Cost after epoch 2800 batch 10: 0.8536244779240086\n",
      "Cost after epoch 2800 batch 11: 0.5652875328138408\n",
      "Cost after epoch 2800 batch 12: 0.24206882668310345\n",
      "Cost after epoch 2800 batch 13: 0.2256341514961134\n",
      "Cost after epoch 2800 batch 14: 0.8279311276678618\n",
      "Cost after epoch 2800 batch 15: 0.27328065090907977\n",
      "Cost after epoch 2800 batch 16: 0.8547917236256198\n",
      "Cost after epoch 2800 batch 17: 0.39679332177385734\n",
      "Cost after epoch 2800 batch 18: 0.3005540208162502\n",
      "Cost after epoch 2800 batch 19: 0.584330662674123\n",
      "Cost after epoch 3500 batch 0: 0.6820937343599249\n",
      "Cost after epoch 3500 batch 1: 0.9845927812057661\n",
      "Cost after epoch 3500 batch 2: 0.5281856155267245\n",
      "Cost after epoch 3500 batch 3: 1.3657943593020916\n",
      "Cost after epoch 3500 batch 4: 0.504470813554658\n",
      "Cost after epoch 3500 batch 5: 0.7156504654720663\n",
      "Cost after epoch 3500 batch 6: 0.7061216358281548\n",
      "Cost after epoch 3500 batch 7: 0.09657219966460652\n",
      "Cost after epoch 3500 batch 8: 1.1572658053713802\n",
      "Cost after epoch 3500 batch 9: 0.4909042641604466\n",
      "Cost after epoch 3500 batch 10: 0.8191599667628059\n",
      "Cost after epoch 3500 batch 11: 0.5513309676459902\n",
      "Cost after epoch 3500 batch 12: 1.6598253195822956\n",
      "Cost after epoch 3500 batch 13: 0.4947925827949007\n",
      "Cost after epoch 3500 batch 14: 0.46533214328248845\n",
      "Cost after epoch 3500 batch 15: 0.8266570427590167\n",
      "Cost after epoch 3500 batch 16: 0.23404849039328765\n",
      "Cost after epoch 3500 batch 17: 0.4454839429917173\n",
      "Cost after epoch 3500 batch 18: 1.1215331554168897\n",
      "Cost after epoch 3500 batch 19: 0.5729177585890871\n",
      "Cost after epoch 4200 batch 0: 1.042685255996253\n",
      "Cost after epoch 4200 batch 1: 0.8866471343878971\n",
      "Cost after epoch 4200 batch 2: 0.22306483684983075\n",
      "Cost after epoch 4200 batch 3: 0.6527780899890345\n",
      "Cost after epoch 4200 batch 4: 0.8299932252629109\n",
      "Cost after epoch 4200 batch 5: 0.44713674225001043\n",
      "Cost after epoch 4200 batch 6: 0.43203340390429473\n",
      "Cost after epoch 4200 batch 7: 0.989727725953493\n",
      "Cost after epoch 4200 batch 8: 0.08709315921864987\n",
      "Cost after epoch 4200 batch 9: 0.5430919949229471\n",
      "Cost after epoch 4200 batch 10: 0.22426360475748727\n",
      "Cost after epoch 4200 batch 11: 0.4760168632238848\n",
      "Cost after epoch 4200 batch 12: 0.9503841561588021\n",
      "Cost after epoch 4200 batch 13: 0.6370019452347642\n",
      "Cost after epoch 4200 batch 14: 0.43402243595639045\n",
      "Cost after epoch 4200 batch 15: 0.43643465130473286\n",
      "Cost after epoch 4200 batch 16: 0.18678708426650528\n",
      "Cost after epoch 4200 batch 17: 0.44477403605854926\n",
      "Cost after epoch 4200 batch 18: 0.8779781070876915\n",
      "Cost after epoch 4200 batch 19: 0.5043866990917556\n",
      "Cost after epoch 4900 batch 0: 0.4622657921613655\n",
      "Cost after epoch 4900 batch 1: 0.8639296814837149\n",
      "Cost after epoch 4900 batch 2: 0.20102453191418745\n",
      "Cost after epoch 4900 batch 3: 0.6338766553691121\n",
      "Cost after epoch 4900 batch 4: 0.6820115373667877\n",
      "Cost after epoch 4900 batch 5: 0.2231599111003339\n",
      "Cost after epoch 4900 batch 6: 0.9709328080845722\n",
      "Cost after epoch 4900 batch 7: 0.6447155246311433\n",
      "Cost after epoch 4900 batch 8: 0.5707110277120534\n",
      "Cost after epoch 4900 batch 9: 0.8858757294584472\n",
      "Cost after epoch 4900 batch 10: 0.5768836641462818\n",
      "Cost after epoch 4900 batch 11: 1.5766776075159525\n",
      "Cost after epoch 4900 batch 12: 0.588266381018731\n",
      "Cost after epoch 4900 batch 13: 0.652216815701756\n",
      "Cost after epoch 4900 batch 14: 0.4471979144490035\n",
      "Cost after epoch 4900 batch 15: 0.4953987138674934\n",
      "Cost after epoch 4900 batch 16: 0.5798485782885254\n",
      "Cost after epoch 4900 batch 17: 0.5299993769355794\n",
      "Cost after epoch 4900 batch 18: 0.26745200916875955\n",
      "Cost after epoch 4900 batch 19: 1.0297691480713362\n",
      "Cost after epoch 5600 batch 0: 0.46540120575215826\n",
      "Cost after epoch 5600 batch 1: 0.333868355490666\n",
      "Cost after epoch 5600 batch 2: 0.701556304025257\n",
      "Cost after epoch 5600 batch 3: 0.8031317744339244\n",
      "Cost after epoch 5600 batch 4: 1.3548967242235774\n",
      "Cost after epoch 5600 batch 5: 0.233555055733909\n",
      "Cost after epoch 5600 batch 6: 0.9378260001202499\n",
      "Cost after epoch 5600 batch 7: 0.8399151342642035\n",
      "Cost after epoch 5600 batch 8: 1.0998138180603052\n",
      "Cost after epoch 5600 batch 9: 0.7535946503934788\n",
      "Cost after epoch 5600 batch 10: 0.7220279049713622\n",
      "Cost after epoch 5600 batch 11: 0.8770643047338004\n",
      "Cost after epoch 5600 batch 12: 0.7102802038561744\n",
      "Cost after epoch 5600 batch 13: 0.40108318715998736\n",
      "Cost after epoch 5600 batch 14: 0.3717023765081274\n",
      "Cost after epoch 5600 batch 15: 0.5416640688915836\n",
      "Cost after epoch 5600 batch 16: 1.1243789364465502\n",
      "Cost after epoch 5600 batch 17: 1.447101108906932\n",
      "Cost after epoch 5600 batch 18: 0.5047728750861245\n",
      "Cost after epoch 5600 batch 19: 1.3071195579104609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 6300 batch 0: 0.5181283740931757\n",
      "Cost after epoch 6300 batch 1: 0.9198355515909609\n",
      "Cost after epoch 6300 batch 2: 1.165063034235894\n",
      "Cost after epoch 6300 batch 3: 0.596190308130074\n",
      "Cost after epoch 6300 batch 4: 0.3264185378387785\n",
      "Cost after epoch 6300 batch 5: 0.6222344552678059\n",
      "Cost after epoch 6300 batch 6: 0.5695103390620434\n",
      "Cost after epoch 6300 batch 7: 0.23285134936350402\n",
      "Cost after epoch 6300 batch 8: 1.0310653954504714\n",
      "Cost after epoch 6300 batch 9: 0.35662542572000033\n",
      "Cost after epoch 6300 batch 10: 0.7570190242768783\n",
      "Cost after epoch 6300 batch 11: 0.7773581490333241\n",
      "Cost after epoch 6300 batch 12: 0.4828422096093965\n",
      "Cost after epoch 6300 batch 13: 0.08859985847778686\n",
      "Cost after epoch 6300 batch 14: 0.435930262190865\n",
      "Cost after epoch 6300 batch 15: 0.42582222929844354\n",
      "Cost after epoch 6300 batch 16: 1.3838763907954348\n",
      "Cost after epoch 6300 batch 17: 0.5603005861333571\n",
      "Cost after epoch 6300 batch 18: 0.8895894073131397\n",
      "Cost after epoch 6300 batch 19: 0.14112270872663127\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.99999999999999%\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [2, 25, 15, 1] \n",
    "activ = [\"relu\", \"relu\", \"sigmoid\"]\n",
    "momentom = 0\n",
    "num_iterations = 7000\n",
    "parameters = L_layer_model_levenperg(train_x, train_y, activ, layers_dims, momentom,learning_rate = 0.01, epochs = num_iterations, print_cost= True,batch_size=10)\n",
    "pred_train = predict(train_x, train_y, parameters, activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def L_layer_model(X, Y, activ, layers_dims, momentom, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "   \n",
    "    np.random.seed(1)\n",
    "    costs = []                         \n",
    "\n",
    "    parameters, dw = initialize_parameters_deep(layers_dims)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "\n",
    "        AL, caches = L_model_forward(X, parameters, activ)\n",
    "\n",
    "        cost = compute_cost(AL, Y)\n",
    "\n",
    "        grads = L_model_backward(AL, Y, caches, activ)\n",
    " \n",
    "        parameters = update_parameters(parameters, grads, learning_rate, momentom, dw)\n",
    "                \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def load_extra_datasets():  \n",
    "    N = 200\n",
    "    noisy_circles = sklearn.datasets.make_circles(n_samples=N, factor=.5, noise=.3)\n",
    "    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n",
    "    blobs = sklearn.datasets.make_blobs(n_samples=N, random_state=5, n_features=2, centers=6)\n",
    "    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n",
    "    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n",
    "    \n",
    "    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L_layer_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-459d825fa735>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mactiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmomentom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL_layer_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'L_layer_model' is not defined"
     ]
    }
   ],
   "source": [
    "layers_dims = [2, 20, 7, 5, 1] \n",
    "activ = [\"relu\", \"relu\", \"relu\", \"sigmoid\"]\n",
    "momentom = 0.5\n",
    "parameters = L_layer_model(train_x, train_y, activ, layers_dims, momentom, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.0%\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ee355d68d2e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_decision_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-20f8749c72fe>\u001b[0m in \u001b[0;36mplot_decision_boundary\u001b[1;34m(X, y, parameters, activ)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Predict the function value for the whole grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Plot the contour and training examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-55c4d6df9c6c>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(X, y, parameters, activ)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "pred_train = predict(train_x, train_y, parameters, activ)\n",
    "plot_decision_boundary(train_x,train_y,parameters,activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
